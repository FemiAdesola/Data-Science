{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FemiAdesola/Data-Science/blob/main/Maintenance_%26_Manufacturing_Department.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M27qF7CTrBqc"
      },
      "source": [
        "# <ins>**THE DATA SCIENCE FOR BUSINESS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ZMlH-gtOxf"
      },
      "source": [
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://drive.google.com/uc?id=1rcxnQuLqFyn8l9hQmdyp-yxSaXhxJPed\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"1000\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1. Predict Defects Using Deep Learning\n",
        "  </td></tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bLpY2prr3qt"
      },
      "source": [
        "# <ins>**Maintenance & Manufacturing Department**\n",
        "+ Artificial Intelligence and Machine Learning are transforming the manufacturing industry. According to the report released by World Economic Forum, these technologies will play significant roles in the fourth industrial revolution. Major areas which can be benefited from this are:\n",
        "  + Maintenance Department\n",
        "  + Production Department\n",
        "  + Supply Chain Department\n",
        "+ Deep learning has been proven to be superior in detecting and localizing defects using imagery data which could significantly improve the production efficiency in the manufacturing industry.\n",
        "+ Great Example from LandingAI:\n",
        "\n",
        "https://landing.ai/defect-detection\n",
        "\n",
        "\n",
        "## <ins>**Case Study**\n",
        "\n",
        "In this case study, we will assume that you work as an Al/ ML consultant.\n",
        "+ You have been hired by a steel manufacturing company in San Diego and you have been tasked to automate the process of detecting and localizing defects found in Steel manufacturing.\n",
        "+ Detecting defects would help in improving the quality of manufacturing as well as in reducing the waste due to production defects.\n",
        "+ The team has collected images of steel surfaces and have approached you to develop a model that could detect and localize defects in real-time.\n",
        "+ You have been provided with 12600 images that contain 4 types of defects, along with their location in the steel surface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxRAp6a7Lso9"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1nzRA5KU0eWo0YPZtSxUWOoMlvooKGCkt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCszOgccu7vv"
      },
      "source": [
        "## <ins>**WHAT IS IMAGE SEGMENTATION?**\n",
        "+ The goal of image segmentation is to understand and extract information from images at the pixel-level.\n",
        "+ Image Segmentation can be used for object recognition and localization which offers tremendous value in many applications such as medical imaging and self-driving cars etc.\n",
        "+ The goal of image segmentation is to train a neural network to produce pixel-wise mask of the image.\n",
        "+ Modern image segmentation techniques are based on deep learning approach which makes use of common architectures such as CNN, FCs (Fully Convolution Networks) and Deep Encoders-Decoders.\n",
        "+ You will be using ResUNet architecture to solve the current task.\n",
        "+ Recall when we applied CNN for image classification problems? We had to convert the image into a vector and possibly add a classification head at the end.\n",
        "+ However, in case of Unet, we convert (encode) the image into a vector followed by up sampling (decode) it back again into an image.\n",
        "+ In case of Unet, the input and output have the same size so the size of the image is preserved.\n",
        "+ For classical CNNs: they are generally used when the entire image is needed to be classified as a class label.\n",
        "+ For Unet: pixel level classification is performed.\n",
        "+ U-net formulates a loss function for every pixel in the input image.\n",
        "+ Softmax function is applied to every pixel which makes the segmentation problem works as a classification problem where classification is performed on every pixel of the image\n",
        "\n",
        "https://aditi-mittal.medium.com/introduction-to-u-net-and-res-net-for-image-segmentation-9afcb432ee2f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKmFmyaGunc7"
      },
      "source": [
        "# <ins>**IMPORT LIBRARIES AND DATASETS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0Cx3743urFY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "import os\n",
        "from google.colab import files\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P_ciLXawMZg",
        "outputId": "3a76ebbd-53c0-4a3e-95d5-6abe50e13914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# You will need to mount your drive using the following commands:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A2fH0Pov5lQ"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1kNILYpkePWnvy4Ntfsgorm55AzexCyay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3kcVUXiwzUk"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1hMEbHCAHE3rsfHA6fR-ELY6c9dkJuAJI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjIiJdM4u1IE"
      },
      "source": [
        "# data containing defect images with segmentation mask\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbC_D1Gnw5_y"
      },
      "source": [
        "# data containing defective and non defective images"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4_wPDKCu5Uc"
      },
      "source": [],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiJTmyEBua4n"
      },
      "source": [],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlszUhNNyrl_"
      },
      "source": [
        "# <ins>**VISUALIZE AND EXPLORE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICj3NLbqqmve"
      },
      "source": [],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZomzExDySgb"
      },
      "source": [],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sddcLXnFzMAy"
      },
      "source": [],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za48tcXcx1FS"
      },
      "source": [
        "# Some images are classified with more than one defect, let's explore this futher\n",
        "# we have one image with 3 types of defects\n",
        "# we have 272 images with 2 types of defects\n",
        "# we have 5201 images with 1 type of defect\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4g-1HFErAUW"
      },
      "source": [],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlKDGvA7rVVL"
      },
      "source": [],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhm-Y9Tlx1H_"
      },
      "source": [],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0QetIIS0ekU"
      },
      "source": [],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iYFwJtG0em_"
      },
      "source": [],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtK2Dozi0epR"
      },
      "source": [
        "# Let's count defective and non defective images\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wug5WIimucRM"
      },
      "source": [],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpb9SQ-W0tfu"
      },
      "source": [
        "# Visualize images with defects along with their corresponding labels\n",
        "# Images are 256 x 1600"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ7GMxpy6fgd"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uIpuNYz75is"
      },
      "source": [],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px2F3RkW8lP-"
      },
      "source": [
        "# Let's try to use the rle2mask on a sample image\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHeb7j-486d8"
      },
      "source": [
        "# Let's show the mask\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRNgXKF98_y6"
      },
      "source": [],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDZhajOg6flc"
      },
      "source": [
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6SI58F7ySeh"
      },
      "source": [
        "# <ins>**UNDERSTAND THE THEORY AND INTUITION BEHIND CONVOLUTIONAL NEURAL NETWORKS, RESNETS, AND TRANSFER LEARNING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CijMDQ9RsWpb"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1HD2FFDD8fonGMyHARfw8ZqaofP3Udek6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhmMxX-LtXkx"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1-HAo3xcPKGoH-gG8495p12o33nUC1j6W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6sP5t2vt5dc"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1zmzg777lS1PGkTyJXA5fPmrJ9mcKneDi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QbYOy9Xt5aa"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1Fd6xV3NwRAhRdFQN9FDjkumynoqcWCzM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRSLmofOqJ2X"
      },
      "source": [
        "# <ins>**BUILD AND TRAIN A DEEP LEARNING MODEL TO DETECT WHETHER A DEFECT IS PRESENT IN AN IMAGE OR NOT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RejG3T3yGP5b"
      },
      "source": [],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obGUGKgs0NJB"
      },
      "source": [
        "# split the data (defective and non defective) into training and testing"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy6vCw-GGZrP"
      },
      "source": [],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79ethEGBGZpJ"
      },
      "source": [],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QEOhBwtIKVv"
      },
      "source": [],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2JD_rBGGZmg"
      },
      "source": [
        "# create a image generator for the training and validation dataset\n",
        "# we will divide the data to training, validation and testing\n",
        "# Training = 9390\n",
        "# validation = 1657\n",
        "# testing = 1950\n",
        "\n",
        "\n",
        "# Create a data generator which scales the data from 0 to 1 and makes validation split of 0.15\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHpRFqN3HYZ8"
      },
      "source": [
        "# Create a data generator for test images\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zq7zMBexYsV"
      },
      "source": [],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBVhEydjxYkb"
      },
      "source": [],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAXdldnsxYah"
      },
      "source": [
        "# freeze the model weights\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMB7E5Tkxetp"
      },
      "source": [
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXcaYKyvxepG"
      },
      "source": [],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtIYCa5CxiCf"
      },
      "source": [
        "# use early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "\n",
        "\n",
        "# save the best model with least validation loss\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTmjUR8GxiBI"
      },
      "source": [
        "# (WARNING TAKES LONG TIME (~90 mins)!)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2p7vb4Cxh8g"
      },
      "source": [
        "# save the trained model architecture for future use"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y95MPj3m5Tr1"
      },
      "source": [
        "# <ins>**ASSESS TRAINED MODEL PERFORMANCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_yya7-p5YsJ"
      },
      "source": [],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-OlLg_a5YoH"
      },
      "source": [
        "# Make prediction (WARNING TAKES LONG TIME (~10 mins)!)\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA8Fi1Dy9qfZ"
      },
      "source": [],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWNMOYCX5fGI"
      },
      "source": [
        "# Since we have used sigmoid activation at the end, our result would contain continuous values from 0 to 1.\n",
        "# The network is initially used to classify whether the image has defect or not\n",
        "# Then these images (defective) is passed through the segmentation network to get the localization and type of defect.\n",
        "# Let's choose 0.01, to make sure, that we omit images from passing through the segmentation network only we are highly certain that it has no defect and if we are not confident, we can pass this image through the segmentation\n",
        "# network\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQFWSO2f5fCS"
      },
      "source": [],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vtRFZV_5iJ6"
      },
      "source": [
        "# since we have used test generator, it limited the images to 1936, due to batch size\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvCW0Lhn5iIg"
      },
      "source": [
        "# Find the accuracy of the model\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrnla_fW5iE5"
      },
      "source": [
        "# Plot the confusion matrix\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Ai_jO35oJh"
      },
      "source": [
        "# Print the classification report\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0GmpAjG3GiH"
      },
      "source": [
        "# <ins>**UNDERSTAND THE THEORY AND INTUITION BEHIND RESUNET (SEGMENTATION)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vi1_uJvu7n7"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1D7mAjdEFv6cIb4UFiXwndJy6enzZQzpb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlZRIwoy1DtF"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1TK1Y9gry62NORdA-EjWD8HJadBZMa_sL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcsK2k-Ev5sF"
      },
      "source": [
        "## <ins>**RESUNET ARCHITECTURE:**\n",
        "1. Encoder or contracting path consist of 4 blocks:\n",
        "  + First block consists of 3×3 convolution layer + Relu + Batch-Normalization\n",
        "  + Remaining three blocks consist of Res-blocks followed by\n",
        "Max-pooling 2x2.\n",
        "2. Bottleneck:\n",
        "  + It is in-between the contracting and expanding path.\n",
        "  + It consist of Res-block followed by up sampling conv layer\n",
        "2x2.\n",
        "3. Expanding or Decoder path consist of 4 blocks:\n",
        "  + 3 blocks following bottleneck consist of Res-blocks followed by up-sampling conv layer 2 x 2\n",
        "  + Final block consist of Res-block followed by 1x1 conv layer.\n",
        "\n",
        "\n",
        "## **RESUNET ADDITIONAL RESOURCES:**\n",
        "\n",
        "Paper #1: https://arxiv.org/abs/1505.04597\n",
        "\n",
        "\n",
        "Paper #2: https://arxiv.org/abs/1904.00592\n",
        "\n",
        "\n",
        "\n",
        "https://aditi-mittal.medium.com/introduction-to-u-net-and-res-net-for-image-segmentation-9afcb432ee2f\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKh1zdDx4_RH"
      },
      "source": [
        "# <ins>**BUILD A RESUNET SEGMENTATION MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASMCztGD5GXC"
      },
      "source": [
        "#spliting the data into train and test data\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x--wEew7fUP"
      },
      "source": [
        "#creating separate list for imageId, classId and rle to pass into the generator"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHxamV1l7fhs"
      },
      "source": [
        "\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86T07x_-7fns"
      },
      "source": [],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCatuc5N7fck"
      },
      "source": [
        "# function to upscale and concatnating the values passsed"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjBTBsj67l8s"
      },
      "source": [
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-ipz-N_8ftR"
      },
      "source": [
        "## Loss function:\n",
        "\n",
        "We need a custom loss function to train this ResUNet.So,  we have used the loss function as it is from https://github.com/nabsabraham/focal-tversky-unet/blob/master/losses.py\n",
        "\n",
        "\n",
        "@article{focal-unet,\n",
        "  title={A novel Focal Tversky loss function with improved Attention U-Net for lesion segmentation},\n",
        "  author={Abraham, Nabila and Khan, Naimul Mefraz},\n",
        "  journal={arXiv preprint arXiv:1810.07842},\n",
        "  year={2018}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t8rk_wY7l3O"
      },
      "source": [],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHrYV3wU8llA"
      },
      "source": [],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykx7wl658lj4"
      },
      "source": [
        "# using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "\n",
        "# save the best model with lower validation loss\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_lmECI58le6"
      },
      "source": [],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwz9H_Xi8rCb"
      },
      "source": [
        "# save the model for future use\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCnoC_QY9LNa"
      },
      "source": [
        "# <ins>**ASSESS TRAINED SEGMENTATION MODEL PERFORMANCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P16wn7yh9jtN"
      },
      "source": [],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1_9kk6rXMVS"
      },
      "source": [
        "# data containing test images for segmentation task\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TlBCIckXMTZ"
      },
      "source": [],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVFRKgBujup0"
      },
      "source": [],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEICzTHWXMRZ"
      },
      "source": [],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8flvRPFXPdw"
      },
      "source": [
        "# create a dataframe for the result"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE4c8jZ4XPiQ"
      },
      "source": [
        "# Let's show the images along with their original (ground truth) masks\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yIWeyObXPnA"
      },
      "source": [
        "# visualize the results (model predictions)"
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}